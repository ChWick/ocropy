#!/usr/bin/env python

from __future__ import print_function

import random as pyrandom
import re
import os.path
import traceback
import argparse
import sys

import numpy as np

import ocrolib
import ocrolib.lstm as lstm
from ocrolib.codec import Codec
from ocrolib import lineest
import traceback
import time
from multiprocessing import Pool
import ocrolib.tfmodel.model as tensorflow_model

np.seterr(divide='raise',over='raise',invalid='raise',under='ignore')

# only one thread to train, do not use GPU
os.environ['OMP_NUM_THREADS'] = "1"
os.environ['CUDA_VISIBLE_DEVICES'] = ""

parser = argparse.ArgumentParser("train an RNN recognizer")

# line normalization
parser.add_argument("-e","--lineest",default="center",
                    help="type of text line estimator, default: %(default)s")
parser.add_argument("-E","--nolineest",action="store_true",
                    help="don't perform line estimation and load .dew.png file")
parser.add_argument("-l","--height",default=48,type=int,
                    help="set the default height for line estimation, default: %(default)s")
parser.add_argument("--dewarp",action="store_true",
                    help="only perform line estimation and output .dew.png file")

# character set
parser.add_argument("-c","--codec",default=[],nargs='*',
                    help="construct a codec from the input text")
parser.add_argument("--repeated_chars_as_single", default=False, action="store_true",
                    help="The codec handles doubled characters as not as two separated chars but as a new single one")

# learning
parser.add_argument("-T","--tensorflow",action="store_true",
                    help="use Tensorflor LSTM and CTC backend")
parser.add_argument("-C","--clstm",action="store_true",
                    help="use C++ LSTM")
parser.add_argument("-r","--lrate",type=float,default=1e-4,
                    help="LSTM learning rate, default: %(default)s")
parser.add_argument("-S","--hiddensize",type=int,default=100,
                    help="# LSTM state units, default: %(default)s")
parser.add_argument("-o","--output",default=None,
                    help="LSTM model file")
parser.add_argument("--output_model_prefix", type=str, default=None,
                    help="Prefix for stored models. This is by default created by the network shape")
parser.add_argument("-F","--savefreq",type=int,default=1000,
                    help="LSTM save frequency, default: %(default)s")
parser.add_argument("--freq_in_s", action="store_true", default=False,
                    help="savefreq is time in seconds instead of steps")
parser.add_argument("--strip",action="store_false",
                    help="strip the model before saving")
parser.add_argument("-N","--ntrain",type=int,default=1000000,
                    help="# lines to train before stopping, default: %(default)s")
parser.add_argument("-t","--tests",default=None,
                    help="test cases for error estimation")
parser.add_argument('--unidirectional',action="store_true",
                    help="use only unidirectional LSTM")
parser.add_argument("--updates",action="store_true",
                    help="verbose LSTM updates")
parser.add_argument('--load',default=None,
                    help="start training with a previously trained model")
parser.add_argument('--load_pretrained', default=False, action="store_true",
                    help="create new model but copy all weights - if possible - to the new model from the load argument")
parser.add_argument('--start',default=-1,type=int,
                    help="manually set the number of already learned lines, which influences the naming and stoping condition, default: %(default)s which will then be overriden by the value saved in the network")
parser.add_argument('-B', "--batch_size", type=int, default=1,
                    help="The number of images that will be learned in parallel")
parser.add_argument('--threads', type=int, default=4,
                    help="The number of threads being used for batch generation")
parser.add_argument('--preload', action="store_true", default=False,
                    help="Load all all files into memory before running the learning algorithm.")
parser.add_argument('--network', type=str, default="lstm=100",
                    help="Network structure that shall be used for training. Eg. 'cnn=60:3x3,pool=2x2,lstm=100")
parser.add_argument('--validation', nargs="+",
                    help="Validation files used for early stopping")
parser.add_argument('--early_stopping_nbest', type=int, default=10,
                    help="Number of models that must be worse than the current best to stop early")
parser.add_argument('--early_stopping_best_model_prefix', type=str, default="best_model",
                    help="The prefix of the best model using early stopping")

# debugging
parser.add_argument("-X","--exec",default="None",dest="execute",
                    help="execute before anything else (usually used for imports)")
parser.add_argument("-v","--verbose",action="store_true")
parser.add_argument("-d","--display",type=int,default=0,
                    help="display output for every nth iteration, where n=DISPLAY, default: %(default)s")
parser.add_argument("-m","--movie",default=None)
parser.add_argument("-M","--moviesample",default=None)
parser.add_argument("-q","--quiet",action="store_true")
parser.add_argument("-Q","--nocheck",action="store_true")
parser.add_argument("-p","--pad",type=int,default=16)

parser.add_argument("files",nargs="*")
args = parser.parse_args()

inputs = ocrolib.glob_all(args.files)
if len(inputs)==0:
    parser.print_help()
    sys.exit(0)

print("# inputs", len(inputs))

if args.validation:
    args.validation = ocrolib.glob_all(args.validation)
else:
    args.validation = []

early_stopping_enabled = len(args.validation) > 0 and args.early_stopping_nbest > 1
early_stopping_best_model = None
early_stopping_best_error = 10000000
early_stopping_best_last_model_iter = 0

# make sure movie mode is used correctly

if args.movie is not None:
    if args.display<2:
        print("you must set --display to some number greater than 1")
        sys.exit(0)

if args.moviesample is None:
    args.moviesample = inputs[0]

# make sure an output file has been set

if args.output is None:
    print("you must give an output file with %d in it, or a prefix")
    sys.exit(0)

if not "%" in args.output:
    if args.clstm:
        oname = args.output+"-%08d.h5"
    else:
        oname = args.output+"-%08d.pyrnn"
else:
    oname = args.output

# get a separate test set, if present

tests = None
if args.tests is not None:
    tests = ocrolib.glob_all(args.tests.split(":"))
print("# tests", len(tests) if tests is not None else "None")

# load the line normalizer

if args.lineest=="center":
    lnorm = lineest.CenterNormalizer()
else:
    raise Exception(args.lineest+": unknown line normalizer")
lnorm.setHeight(args.height)

# The `codec` maps between strings and arrays of integers.

if args.codec!=[]:
    print("# building codec")
    codec = Codec(double_as_extra=args.repeated_chars_as_single)
    charset = set()
    print(args.codec)
    for fname in ocrolib.glob_all(args.codec):
        transcript = ocrolib.read_text(fname)
        l = codec.split(lstm.normalize_nfkc(transcript))
        charset = charset.union(l)
    charset = sorted(list(charset))
    charset = [c for c in charset if c>" " and c!="~"]
else:
    print("# using default codec")
    charset = sorted(list(set(list(lstm.ascii_labels) + list(ocrolib.chars.default))))

charset = [""," ","~",]+[c for c in charset if c not in [" ","~"]]

print("# charset size", len(charset), end=' ')
if len(charset)<200:
    print("[" + u"".join(charset).encode("utf-8") + "]")
else:
    s = "".join(charset)
    print("[" + s[:20], "...", s[-20:] + "]")
codec = Codec(double_as_extra=args.repeated_chars_as_single).init(charset)


# Load an existing network or construct a new one
# Somewhat convoluted logic for dealing with old style Python
# modules and new style C++ LSTM networks.

def save_lstm(fname,network):
    if args.tensorflow:
        network.save(fname)
    elif args.clstm:
        network.lstm.save(fname)
    else:
        if args.strip:
            network.clear_log()
            for x in network.walk(): x.preSave()
        ocrolib.save_object(fname,network)
        if args.strip:
            for x in network.walk(): x.postLoad()


def load_lstm(fname, codec):
    if args.tensorflow:
        import ocrolib.tensorflow as tf_backend
        network = tf_backend.SequenceRecognizer.load(fname,
                                                     model_settings=tensorflow_model.Model.parse_model_settings(args.network),
                                                     pretrained=args.load_pretrained, codec=codec)
    elif args.clstm:
        network = lstm.SeqRecognizer(args.height,args.hiddensize,
            codec=codec,
            normalize=lstm.normalize_nfkc)
        import clstm
        mylstm = clstm.make_BIDILSTM()
        mylstm.init(network.No,args.hiddensize,network.Ni)
        mylstm.load(fname)
        network.lstm = clstm.CNetwork(mylstm)
    else:
        network = ocrolib.load_object(last_save)
        network.upgrade()
        for x in network.walk(): x.postLoad()

    # if a model was loaded we must change the local codec in any case
    # either resize the codec of the network if a codec is given
    # or use the loaded codec directly
    if args.codec != []:
        # resize the network codec (including the network weights)
        codec = network.resizeCodec(codec)
    else:
        # the local codec is simply the local codec
        codec = network.codec

    return network, codec

if args.load:
    print("# loading", args.load)
    last_save = args.load
    network, codec = load_lstm(args.load, codec)
else:
    last_save = None
    if args.tensorflow:
        import ocrolib.tfmodel as tf_backend
        network = tf_backend.SequenceRecognizer(args.height,
                                                model_settings=tensorflow_model.Model.parse_model_settings(args.network),
                                                codec=codec, normalize=lstm.normalize_nfkc, threads=args.threads)
    else:
        network = lstm.SeqRecognizer(args.height,args.hiddensize,
            codec=codec,
            normalize=lstm.normalize_nfkc)
        if args.clstm:
            import clstm
            mylstm = clstm.make_BIDILSTM()
            mylstm.init(network.No,args.hiddensize,network.Ni)
            network.lstm = clstm.CNetwork(mylstm)

if getattr(network,"lnorm",None) is None:
    network.lnorm = lnorm

network.upgrade()
if network.last_trial%100==99: network.last_trial += 1
print("# last_trial", network.last_trial)


# set up the learning rate

network.setLearningRate(args.lrate,0.9)
if args.updates: network.lstm.verbose = 1

# used for plotting

if args.display > 0:
    import matplotlib.pyplot as plt
    plt.ion()
    plt.rc('xtick',labelsize=7)
    plt.rc('ytick',labelsize=7)
    plt.rcParams.update({"font.size":7})


def cleandisp(s):
    return re.sub('[$]',r'#',s)


def plot_network_info(network,transcript,pred,gta):
    plt.subplot(511)
    plt.imshow(line.T,cmap=plt.cm.gray)
    plt.title(cleandisp(transcript))
    plt.subplot(512)
    plt.gca().set_xticks([])
    plt.imshow(network.outputs.T[1:],vmin=0,cmap=plt.cm.hot)
    plt.title(cleandisp(pred[:len(transcript)]))
    plt.subplot(513)
    plt.imshow(network.aligned.T[1:],vmin=0,cmap=plt.cm.hot)
    plt.title(cleandisp(gta[:len(transcript)]))
    plt.subplot(514)
    plt.plot(network.outputs[:,0],color='yellow',linewidth=3,alpha=0.5)
    plt.plot(network.outputs[:,1],color='green',linewidth=3,alpha=0.5)
    plt.plot(np.amax(network.outputs[:,2:],axis=1),color='blue',linewidth=3,alpha=0.5)
    plt.plot(network.aligned[:,0],color='orange',linestyle='dashed',alpha=0.7)
    plt.plot(network.aligned[:,1],color='green',linestyle='dashed',alpha=0.5)
    plt.plot(np.amax(network.aligned[:,2:],axis=1),color='blue',linestyle='dashed',alpha=0.5)
    plt.subplot(515)
    plt.gca().set_yscale('log')
    r = 10000
    errs = network.errors(range=r,smooth=100)
    xs = np.arange(len(errs))+network.last_trial-len(errs)
    plt.plot(xs,errs,color='black')
    plt.plot(xs,network.errors(range=r),color='black',alpha=0.4)
    plt.plot(xs,network.cerrors(range=r,smooth=100),color='red',linestyle='dashed')

start = args.start if args.start>=0 else network.last_trial

def load_data(fname):
    try:
        base,_ = ocrolib.allsplitext(fname)
        line = ocrolib.read_image_gray(fname)
        transcript = ocrolib.read_text(base+".gt.txt")

        if not args.nolineest:
            assert "dew.png" not in fname,"don't dewarp already dewarped lines"
            network.lnorm.measure(np.amax(line)-line)
            line = network.lnorm.normalize(line,cval=np.amax(line))
        else:
            assert "dew.png" in fname,"input must already be dewarped"

        if line.size < 10 or np.amax(line) == np.amin(line):
            raise UserWarning("EMPTY-INPUT")


        line = line * 1.0/np.amax(line)
        line = np.amax(line)-line
        line = line.T
        if args.pad>0:
            w = line.shape[1]
            line = np.vstack([np.zeros((args.pad,w)),line,np.zeros((args.pad,w))])
        cs = np.array(codec.encode(transcript),'i')

        return fname, line, cs, transcript
    except Exception as e:
        # Skip invalid lines
        print(e)
        return fname, None, None, None




thread_pool = Pool(processes=max(1, args.threads))
loaded_validation_data = []
loaded_data = {}
if args.preload:
    print("Preloading data, this might take a while")
    if args.threads > 1:
        data = thread_pool.map(load_data, inputs)
    else:
        data = map(load_data, inputs)

    for fname, line, cs, transcript in data:
        if line is not None:
            loaded_data[fname] = (fname, line, cs, transcript)
        else:
            inputs.remove(fname)

    print("All data loaded: size %s" % len(inputs))


if early_stopping_enabled:
    print("Preloading validation data for early stopping, this might take a while")
    if args.threads > 1:
        data = thread_pool.map(load_data, args.validation)
    else:
        data = map(load_data, args.validation)

    for fname, line, cs, transcript in data:
        if line is not None:
            loaded_validation_data.append((fname, line, cs, transcript))
        else:
            args.validation.remove(fname)

    print("All validation data loaded: size %s" % len(args.validation))

global_start_time = time.time()
last_save_time = time.time()

total_train_time = 0
total_trial_time = 0
for trial in range(start,args.ntrain):
    #if (trial + 1) % 100000 == 0:
    #    args.lrate *= 0.1
    #    print("Settings learning rate to %f" % args.lrate)
    #    network.setLearningRate(args.lrate)

    trial_start = time.time()
    network.last_trial = trial+1

    do_display = (args.display>0 and trial%args.display==0)
    do_update = 1

    if args.movie and do_display:
        fname = args.moviesample
        do_update = 0
    else:
        fname = pyrandom.sample(inputs,args.batch_size)


    # generate data
    try:
        if args.preload:
            # use preloaded data
            data = [loaded_data[name] for name in fname]
        elif args.batch_size > 1 and args.threads > 1:
            # workaround to support keyboard interrupt
            data = thread_pool.map(load_data, fname)
            # data = thread_pool.map(load_data, fname)
        else:
            # not parallel
            data = map(load_data, fname)

    except (IOError, UserWarning) as e:
        print("ERROR", e)
        continue

    all_fnames, all_lines, all_cs, all_transcriptions = zip(*data)


    train_start = time.time()
    try:
        if args.tensorflow:
            pcs = network.trainSequence(all_lines, all_cs,update=do_update,key=fname)
        else:
            pcs = network.trainSequence(all_lines[0], all_cs[0],update=do_update,key=fname[0])

        _, line, cs, transcript = data[0]
    except FloatingPointError as e:
        print("# oops, got FloatingPointError", e)
        traceback.print_exc()
        network, codec = load_lstm(last_save, codec)
    except lstm.RangeError as e:
        continue
    train_end = time.time()
    pred = "".join(codec.decode(pcs))
    #acs = lstm.translate_back(network.aligned)
    #gta = "".join(codec.decode(acs))
    if not args.quiet:
        print("%d %.6f %.6f %s" % (trial, np.mean(network.error_log), np.mean(network.cerror_log), line.shape), fname[0])
        print("   TRU: %s" % repr(transcript))
        #print("   ALN:", repr(gta[:len(transcript)+5]))
        print("   OUT: %s" % repr(pred[:len(transcript)+5]))

    pred = re.sub(' ','_',pred)
    #gta = re.sub(' ','_',gta)


    # Save file
    file_saved = False
    if not args.freq_in_s and (trial+1)%args.savefreq==0:
        ofile = oname%(trial+1)+".gz"
        print("# saving", ofile)
        save_lstm(ofile,network)
        last_save = ofile
        file_saved = True

    if args.freq_in_s and time.time() - last_save_time > args.savefreq:
        ofile = oname % (time.time() - global_start_time) + ".gz"
        save_lstm(ofile, network)
        last_save = ofile
        last_save_time = last_save_time + args.savefreq
        file_saved = True



    if do_display:
        plt.figure("training",figsize=(1400//75,800//75),dpi=75)
        plt.clf()
        plt.gcf().canvas.set_window_title(args.output)
        plot_network_info(network,transcript,pred,gta)
        plt.ginput(1,0.01)
        if args.movie is not None:
            plt.draw()
            plt.savefig("%s-%08d.png"%(args.movie,trial),bbox_inches=0)
    trial_end = time.time()
    print(" * total time %f" % (trial_end - trial_start))
    print(" * train time %f" % (train_end - train_start))

    total_trial_time += int((trial_end - trial_start) * 1000)
    total_train_time += int((train_end - train_start) * 1000)

    print(" * Avg. Time Per Trial: %f" % (total_trial_time / (trial + 1) / 1000.0))
    print(" * Avg. Time Per Train: %f" % (total_train_time / (trial + 1) / 1000.0))

    # check early stopping
    if early_stopping_enabled and file_saved:
        print("Checking early stopping model")
        total_err = 0
        total_chars = 0
        for i in range(0, len(loaded_validation_data), args.batch_size):
            data = loaded_validation_data[i:i+args.batch_size]
            all_fnames, all_lines, all_cs, all_transcriptions = zip(*data)
            all_decoded = network.decode_sequences(all_lines)
            for decoded, trans in zip(all_decoded, all_transcriptions):
                txt = decoded
                total_err += ocrolib.edist.levenshtein(txt, trans)
                total_chars += len(trans)

        if total_chars > 0:
            error_rate = float(total_err) / total_chars
        else:
            error_rate = 1

        print(" * Got error rate of %f" % error_rate)
        if error_rate < early_stopping_best_error:
            early_stopping_best_error = error_rate
            early_stopping_best_model = last_save
            early_stopping_best_last_model_iter = 1
            print(" * Better model found!")
        else:
            # no better model
            early_stopping_best_last_model_iter += 1
            print(" * No better model found! Current best %s at iter %d"
                  % (early_stopping_best_model, early_stopping_best_last_model_iter))

        if early_stopping_best_last_model_iter >= args.early_stopping_nbest:
            print("Early stopping now.")
            break


if early_stopping_enabled:
    print("Copying current best model")
    import shutil
    output_dir = os.path.dirname(args.output)
    model_files = [os.path.join(output_dir, f) for f in os.listdir(output_dir)
                   if os.path.join(output_dir, f).startswith(early_stopping_best_model)]

    for model_file in model_files:
        # expected model ends with .pyrnn.gz*, '*' is tensorflow additional data
        ext = model_file[model_file.rfind(".pyrnn.gz"):]
        best_model = args.output + args.early_stopping_best_model_prefix + ext
        shutil.copy(model_file, best_model)
        print("Wrote best model with error rate %f to '%s'" % (early_stopping_best_error, best_model))
